{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ya allah\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import inshallah as ins\n",
    "from sklearn.impute import KNNImputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from geopy.distance import distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>vesselId</th>\n",
       "      <th>time</th>\n",
       "      <th>scaling_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51734</th>\n",
       "      <td>51734</td>\n",
       "      <td>61e9f3a8b937134a3c4bfdf3</td>\n",
       "      <td>2024-05-12 23:59:58</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51735</th>\n",
       "      <td>51735</td>\n",
       "      <td>61e9f3b4b937134a3c4bfe77</td>\n",
       "      <td>2024-05-12 23:59:58</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51736</th>\n",
       "      <td>51736</td>\n",
       "      <td>61e9f46cb937134a3c4c02b7</td>\n",
       "      <td>2024-05-12 23:59:58</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51737</th>\n",
       "      <td>51737</td>\n",
       "      <td>61e9f465b937134a3c4c0269</td>\n",
       "      <td>2024-05-12 23:59:58</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51738</th>\n",
       "      <td>51738</td>\n",
       "      <td>61e9f3adb937134a3c4bfe39</td>\n",
       "      <td>2024-05-12 23:59:58</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                  vesselId                time  scaling_factor\n",
       "51734  51734  61e9f3a8b937134a3c4bfdf3 2024-05-12 23:59:58             0.1\n",
       "51735  51735  61e9f3b4b937134a3c4bfe77 2024-05-12 23:59:58             0.1\n",
       "51736  51736  61e9f46cb937134a3c4c02b7 2024-05-12 23:59:58             0.1\n",
       "51737  51737  61e9f465b937134a3c4c0269 2024-05-12 23:59:58             0.1\n",
       "51738  51738  61e9f3adb937134a3c4bfe39 2024-05-12 23:59:58             0.1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../CSV/big_files/ais_train.csv\", sep=\"|\")\n",
    "test = pd.read_csv(\"../CSV/ais_test.csv\", sep=\",\")\n",
    "\n",
    "test[\"time\"] = pd.to_datetime(test[\"time\"])\n",
    "\n",
    "data[\"time\"] = pd.to_datetime(data[\"time\"])\n",
    "data[\"sog\"] = data[\"sog\"]*1.944 #Knots to m/s\n",
    "data[\"cog\"] = np.pi * data[\"cog\"] / 180\n",
    "\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floor_to_nearest_5th_day(date, start_date=pd.Timestamp(\"2024-01-01\")):\n",
    "    days_since_start = (date - start_date).days\n",
    "    floored_days = 5 * np.floor(days_since_start / 5)\n",
    "    nearest_5th_day = start_date + pd.Timedelta(days=floored_days)\n",
    "    return nearest_5th_day\n",
    "\n",
    "def calc_vx(row):\n",
    "    return row[\"sog\"]*np.cos(row[\"cog\"])\n",
    "\n",
    "def calc_vy(row):\n",
    "    return row[\"sog\"]*np.sin(row[\"cog\"])\n",
    "\n",
    "def normalize_lat_lon(lat, lon):\n",
    "    \"\"\"\n",
    "    Normalizes extreme latitude and longitude values, ensuring:\n",
    "    - Latitude is constrained between [-90, 90] with appropriate longitude shifts.\n",
    "    - Longitude is wrapped to be within [-180, 180].\n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle extreme latitude values\n",
    "    while lat > 90 or lat < -90:\n",
    "        if lat > 90:\n",
    "            lat = 180 - lat\n",
    "            lon += 180\n",
    "        elif lat < -90:\n",
    "            lat = -180 - lat\n",
    "            lon += 180\n",
    "    \n",
    "    # Normalize longitude using modulo to bring it within [-180, 180]\n",
    "    lon = ((lon + 180) % 360) - 180\n",
    "    \n",
    "    return lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro = []\n",
    "count = 0\n",
    "\n",
    "for i in data[\"vesselId\"].unique():\n",
    "    count += 1\n",
    "\n",
    "    boat = data[data[\"vesselId\"] == i].copy().reset_index(drop=True)\n",
    "    \n",
    "    #Deltas\n",
    "    boat[\"delta_time\"] = (boat[\"time\"] - boat[\"time\"].shift(1)).dt.total_seconds()\n",
    "\n",
    "    boat[\"delta_lat\"] = boat[\"latitude\"] - boat[\"latitude\"].shift(1)\n",
    "    boat[\"delta_lon\"] = boat[\"longitude\"] - boat[\"longitude\"].shift(1)\n",
    "\n",
    "    #5 Day Intervals\n",
    "    boat[\"5d_interval\"] = boat[\"time\"].map(floor_to_nearest_5th_day)\n",
    "    boat[\"delta_5d\"] = (boat[\"time\"] - boat[\"5d_interval\"]).dt.total_seconds()\n",
    "    boat[\"new_int\"] = (boat[\"5d_interval\"] != boat[\"5d_interval\"].shift(-1))\n",
    "\n",
    "    # Velocities and Wierd ahh lags\n",
    "    boat[\"v_x\"] = boat[\"sog\"] * np.cos(boat[\"cog\"])\n",
    "    boat[\"v_y\"] = boat[\"sog\"] * np.sin(boat[\"cog\"])\n",
    "    boat[\"delta_lat_lag\"] = np.nan\n",
    "    boat[\"delta_lon_lag\"] = np.nan\n",
    "    boat[\"lat_lag\"] = np.nan\n",
    "    boat[\"lon_lag\"] = np.nan\n",
    "\n",
    "    for j,row in boat.iterrows():\n",
    "        if row[\"new_int\"] and j != 0:\n",
    "            boat.at[j, \"v_x\"] = calc_vx(row)\n",
    "            boat.at[j, \"v_y\"] = calc_vy(row)\n",
    "\n",
    "            boat.at[j, \"delta_lat_lag\"] = boat.at[j-1, \"delta_lat\"]\n",
    "            boat.at[j, \"delta_lon_lag\"] = boat.at[j-1, \"delta_lon\"]\n",
    "\n",
    "            boat.at[j, \"lat_lag\"] = boat.at[j-1, \"latitude\"]\n",
    "            boat.at[j, \"lon_lag\"] = boat.at[j-1, \"longitude\"]\n",
    "\n",
    "    boat[\"v_x\"].ffill(inplace=True)\n",
    "    boat[\"v_y\"].ffill(inplace=True)\n",
    "    boat[\"delta_lat_lag\"].ffill(inplace=True)\n",
    "    boat[\"delta_lon_lag\"].ffill(inplace=True)\n",
    "    boat[\"lat_lag\"].ffill(inplace=True)\n",
    "    boat[\"lon_lag\"].ffill(inplace=True)\n",
    "\n",
    "    boat[\"v_x\"].bfill(inplace=True)\n",
    "    boat[\"v_y\"].bfill(inplace=True)\n",
    "    boat[\"delta_lat_lag\"].bfill(inplace=True)\n",
    "    boat[\"delta_lon_lag\"].bfill(inplace=True)\n",
    "    boat[\"lat_lag\"].bfill(inplace=True)\n",
    "    boat[\"lon_lag\"].bfill(inplace=True)\n",
    "    \n",
    "\n",
    "    #Cleaning\n",
    "    boat.dropna(inplace=True)\n",
    "    boat.drop(columns=[\"5d_interval\", \"new_int\", \"heading\", \"rot\", \"navstat\", \"etaRaw\", \"portId\"], inplace=True)\n",
    "\n",
    "    #Recreate OG dataframe\n",
    "    for _,rows in boat.iterrows():\n",
    "        pro.append(rows.to_dict())\n",
    "\n",
    "\n",
    "processed = pd.DataFrame(pro)\n",
    "processed.sort_values(\"time\", inplace=True)\n",
    "processed.to_csv(\"processed.csv\", sep=\"|\")\n",
    "processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cog</th>\n",
       "      <th>sog</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vesselId</th>\n",
       "      <th>delta_time</th>\n",
       "      <th>delta_lat</th>\n",
       "      <th>delta_lon</th>\n",
       "      <th>delta_5d</th>\n",
       "      <th>delta_lat_lag</th>\n",
       "      <th>delta_lon_lag</th>\n",
       "      <th>lat_lag</th>\n",
       "      <th>lon_lag</th>\n",
       "      <th>v_x</th>\n",
       "      <th>v_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208776</th>\n",
       "      <td>2024-01-19 14:57:07</td>\n",
       "      <td>3.996804</td>\n",
       "      <td>26.8272</td>\n",
       "      <td>-17.33788</td>\n",
       "      <td>-149.58229</td>\n",
       "      <td>61e9f3aeb937134a3c4bfe3d</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>-0.01565</td>\n",
       "      <td>-0.07867</td>\n",
       "      <td>313027.0</td>\n",
       "      <td>-0.01434</td>\n",
       "      <td>0.01265</td>\n",
       "      <td>8.80894</td>\n",
       "      <td>-79.53719</td>\n",
       "      <td>-25.308525</td>\n",
       "      <td>11.963285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208963</th>\n",
       "      <td>2024-01-19 15:18:20</td>\n",
       "      <td>3.246312</td>\n",
       "      <td>22.7448</td>\n",
       "      <td>-17.40630</td>\n",
       "      <td>-149.62208</td>\n",
       "      <td>61e9f3aeb937134a3c4bfe3d</td>\n",
       "      <td>1273.0</td>\n",
       "      <td>-0.06842</td>\n",
       "      <td>-0.03979</td>\n",
       "      <td>314300.0</td>\n",
       "      <td>-0.01434</td>\n",
       "      <td>0.01265</td>\n",
       "      <td>8.80894</td>\n",
       "      <td>-79.53719</td>\n",
       "      <td>-25.308525</td>\n",
       "      <td>11.963285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209060</th>\n",
       "      <td>2024-01-19 15:25:20</td>\n",
       "      <td>3.263766</td>\n",
       "      <td>12.2472</td>\n",
       "      <td>-17.42397</td>\n",
       "      <td>-149.62541</td>\n",
       "      <td>61e9f3aeb937134a3c4bfe3d</td>\n",
       "      <td>420.0</td>\n",
       "      <td>-0.01767</td>\n",
       "      <td>-0.00333</td>\n",
       "      <td>314720.0</td>\n",
       "      <td>-0.01434</td>\n",
       "      <td>0.01265</td>\n",
       "      <td>8.80894</td>\n",
       "      <td>-79.53719</td>\n",
       "      <td>-25.308525</td>\n",
       "      <td>11.963285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216451</th>\n",
       "      <td>2024-01-20 05:56:50</td>\n",
       "      <td>4.014257</td>\n",
       "      <td>30.1320</td>\n",
       "      <td>-17.70921</td>\n",
       "      <td>-149.87776</td>\n",
       "      <td>61e9f3aeb937134a3c4bfe3d</td>\n",
       "      <td>52290.0</td>\n",
       "      <td>-0.28524</td>\n",
       "      <td>-0.25235</td>\n",
       "      <td>367010.0</td>\n",
       "      <td>-0.01434</td>\n",
       "      <td>0.01265</td>\n",
       "      <td>8.80894</td>\n",
       "      <td>-79.53719</td>\n",
       "      <td>-25.308525</td>\n",
       "      <td>11.963285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216590</th>\n",
       "      <td>2024-01-20 06:16:56</td>\n",
       "      <td>4.101524</td>\n",
       "      <td>28.9656</td>\n",
       "      <td>-17.76261</td>\n",
       "      <td>-149.94901</td>\n",
       "      <td>61e9f3aeb937134a3c4bfe3d</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>-0.05340</td>\n",
       "      <td>-0.07125</td>\n",
       "      <td>368216.0</td>\n",
       "      <td>-0.01434</td>\n",
       "      <td>0.01265</td>\n",
       "      <td>8.80894</td>\n",
       "      <td>-79.53719</td>\n",
       "      <td>-25.308525</td>\n",
       "      <td>11.963285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      time       cog      sog  ...   lon_lag        v_x        v_y\n",
       "208776 2024-01-19 14:57:07  3.996804  26.8272  ... -79.53719 -25.308525  11.963285\n",
       "208963 2024-01-19 15:18:20  3.246312  22.7448  ... -79.53719 -25.308525  11.963285\n",
       "209060 2024-01-19 15:25:20  3.263766  12.2472  ... -79.53719 -25.308525  11.963285\n",
       "216451 2024-01-20 05:56:50  4.014257  30.1320  ... -79.53719 -25.308525  11.963285\n",
       "216590 2024-01-20 06:16:56  4.101524  28.9656  ... -79.53719 -25.308525  11.963285\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed = pd.read_csv(\"processed.csv\", sep=\"|\")\n",
    "processed[\"time\"] = pd.to_datetime(processed[\"time\"])\n",
    "processed.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "processed[processed[\"vesselId\"] == \"61e9f3aeb937134a3c4bfe3d\"][50:100].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['delta_time', 'delta_5d', 'delta_lat_lag', 'delta_lon_lag', 'lat_lag', 'lon_lag', 'v_x', 'v_y']\n",
      "Starting LGBTQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FEATURES = [\"delta_time\", \"delta_5d\", \"delta_lat_lag\", \"delta_lon_lag\", \"lat_lag\", \"lon_lag\", \"v_x\", \"v_y\"]\n",
    "print(FEATURES)\n",
    "\n",
    "n = 36129\n",
    "n_rows = processed[FEATURES].shape[0]\n",
    "train, test = processed.head(n_rows-n), processed.tail(n)\n",
    "y_test = test[[\"delta_lat\", \"delta_lon\"]]\n",
    "\n",
    "# print(\"Starting XGBoost\")\n",
    "# xgb = XGBRegressor(n_estimators=4000, learning_rate=0.01, max_depth=10)\n",
    "# xgb.fit(processed[FEATURES], processed[[\"delta_lat\", \"delta_lon\"]])\n",
    "\n",
    "print(\"Starting LGBTQ\")\n",
    "lgbtq = LGBMRegressor(metric=\"mse\")\n",
    "lgbtq.fit(processed[FEATURES], processed[[\"delta_lat\", \"delta_lon\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterative setup\n",
    "test = pd.read_csv(\"../CSV/ais_test.csv\", sep=\",\")\n",
    "test[\"time\"] = pd.to_datetime(test[\"time\"])\n",
    "\n",
    "stats = {}\n",
    "n = 3\n",
    "\n",
    "for i in test[\"vesselId\"].unique():\n",
    "    trained = processed[processed[\"vesselId\"] == i]\n",
    "    boat = test[test[\"vesselId\"] == i].reset_index(drop=True)\n",
    "    \n",
    "    last_5d = floor_to_nearest_5th_day(boat.iloc[0][\"time\"])\n",
    "    last_time = trained.iloc[-1][\"time\"]\n",
    "\n",
    "    delta_lat_lag = trained.iloc[-1][\"delta_lat_lag\"]\n",
    "    delta_lon_lag = trained.iloc[-1][\"delta_lon_lag\"]\n",
    "\n",
    "    lat_lag = trained.iloc[-1][\"lat_lag\"]\n",
    "    lon_lag = trained.iloc[-1][\"lon_lag\"]\n",
    "\n",
    "    v_x = trained.iloc[-1][\"sog\"] * np.cos(trained.iloc[-1][\"cog\"])\n",
    "    v_y = trained.iloc[-1][\"sog\"] * np.sin(trained.iloc[-1][\"cog\"])\n",
    "\n",
    "    stats[i] = {\"last_5d\": last_5d, \"last_time\": last_time, \"delta_lat_lag\": delta_lat_lag,\n",
    "                \"delta_lon_lag\": delta_lon_lag, \"lat_lag\": lat_lag, \"lon_lag\": lon_lag,\n",
    "                \"v_x\": v_x, \"v_y\": v_y}\n",
    "\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FEATURES)\n",
    "\n",
    "def get_velocities(x_0, x_1, delta_time) -> tuple:\n",
    "    dist = distance((x_0[0], x_0[1]), (x_1[0], x_1[1])).km * 1000\n",
    "    speed = dist / delta_time\n",
    "\n",
    "    adj, opp = x_1[1] - x_1[0], x_0[1] - x_0[0]\n",
    "\n",
    "    v_x = speed * (adj / dist)\n",
    "    v_y = speed * (opp / dist)\n",
    "\n",
    "    return (v_x, v_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "test = pd.read_csv(\"../CSV/ais_test.csv\", sep=\",\")\n",
    "test[\"time\"] = pd.to_datetime(test[\"time\"])\n",
    "\n",
    "for i in test[\"vesselId\"].unique():\n",
    "    boat = test[test[\"vesselId\"] == i].reset_index(drop=True)\n",
    "\n",
    "    #Delta time\n",
    "    boat[\"delta_time\"] = boat[\"time\"] - boat[\"time\"].shift(1)\n",
    "    boat.at[0, \"delta_time\"] = boat.at[0, \"time\"] - stats[i][\"last_time\"]\n",
    "    boat[\"delta_time\"] = boat[\"delta_time\"].dt.total_seconds()\n",
    "\n",
    "    boat[\"delta_5d\"] = boat[\"time\"] - stats[i][\"last_5d\"]\n",
    "    boat[\"delta_5d\"] = boat[\"delta_5d\"].dt.total_seconds()\n",
    "\n",
    "    #Rest of initial conditions\n",
    "    for stat in stats[i].keys():\n",
    "        if stat != \"last_5d\" and stat != \"last_time\":\n",
    "            boat.at[0, stat] = stats[i][stat]\n",
    "\n",
    "    boat[\"latitude\"] = np.nan\n",
    "    boat[\"longitude\"] = np.nan\n",
    "\n",
    "    #Iterative\n",
    "    for j in range(1, boat.shape[0]+1):\n",
    "        current_input = boat[FEATURES][j-1:j]\n",
    "        current_pred = xgb.predict(current_input)[0]\n",
    "\n",
    "        new_lat, new_lon = float(current_input[\"lat_lag\"] + current_pred[0]), float(current_input[\"lon_lag\"] + current_pred[1])\n",
    "        latlon = normalize_lat_lon(new_lat, new_lon)\n",
    "        new_lat, new_lon = latlon[0], latlon[1]\n",
    "\n",
    "        boat.at[j-1, \"latitude\"] = new_lat\n",
    "        boat.at[j-1, \"longitude\"] = new_lon\n",
    "\n",
    "        #Create next input\n",
    "        boat.at[j, \"lat_lag\"] = new_lat\n",
    "        boat.at[j, \"lon_lag\"] = new_lon\n",
    "\n",
    "        boat.at[j, \"delta_lat_lag\"] = current_pred[0]\n",
    "        boat.at[j, \"delta_lon_lag\"] = current_pred[1]\n",
    "\n",
    "        prev_pos = (float(current_input[\"lat_lag\"]), float(current_input[\"lon_lag\"]))\n",
    "        new_pos = (float(new_lat), float(new_lon))\n",
    "        delta_time = boat.at[j, \"delta_time\"]\n",
    "\n",
    "        v = get_velocities(prev_pos, new_pos, delta_time)\n",
    "\n",
    "        boat.at[j, \"v_x\"] = v[0]\n",
    "        boat.at[j, \"v_y\"] = v[1]\n",
    "        \n",
    "    boat.dropna(inplace=True)\n",
    "\n",
    "    for _,row in boat.iterrows():\n",
    "        final.append(row.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final).sort_values(\"ID\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel = \"61e9f469b937134a3c4c029b\"\n",
    "\n",
    "fig = (\n",
    "    ins.visualize_vessel_movements(processed[processed[\"vesselId\"] == vessel])\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = (\n",
    "    ins.visualize_vessel_movements(df[df[\"vesselId\"] == vessel])\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"longitude_predicted\"] = df[\"longitude\"]\n",
    "df[\"latitude_predicted\"] = df[\"latitude\"]\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "df[[\"longitude_predicted\", \"latitude_predicted\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df[[\"longitude_predicted\", \"latitude_predicted\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"longitude_predicted\", \"latitude_predicted\"]].to_csv(\"res.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
